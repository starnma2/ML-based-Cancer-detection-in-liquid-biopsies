import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    roc_curve,
    confusion_matrix,
    classification_report
)

# Set random seed for reproducibility
RANDOM_STATE = 13
np.random.seed(RANDOM_STATE)

#####################################################################

from sklearn.model_selection import GridSearchCV

class TopVarianceSelector(BaseEstimator, TransformerMixin):
    """Select top-k features with highest variance."""
    def __init__(self, k=50):
        self.k = k

    def fit(self, X, y=None):
        # Handle DataFrame and numpy array
        if isinstance(X, pd.DataFrame):
            self.feature_names_in_ = X.columns
            variances = X.var(axis=0).values  # variance per column
        else:
            X = np.asarray(X)
            self.feature_names_in_ = np.arange(X.shape[1])
            variances = X.var(axis=0)

        # indices of top-k variances (descending)
        self.indices_ = np.argsort(variances)[::-1][:self.k]
        self.variances_ = variances
        return self

    def transform(self, X):
        if isinstance(X, pd.DataFrame):
            return X.iloc[:, self.indices_]
        else:
            X = np.asarray(X)
            return X[:, self.indices_]

    def get_feature_names_out(self, input_features=None):
        # Names of the selected TFs
        return np.array(self.feature_names_in_)[self.indices_]

pipe = Pipeline([
    ("scaling", StandardScaler()),
    ("var_select", TopVarianceSelector(k=50)),   # 50 most variable TFs
    ("xgb", XGBClassifier(
        n_estimators=200,
        max_depth=4,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )),
])

param_grid = {
    'xgb__max_depth': [3, 5, 7],
    'xgb__learning_rate': [0.01, 0.1, 0.3],
    'xgb__n_estimators': [50, 100, 200],
}

clf_cv = GridSearchCV(
    pipe,
    param_grid=param_grid,
    cv=10,
    scoring='roc_auc',
    n_jobs=-1,
    verbose=1,
    refit=True
)

clf_cv.fit(X_train, y_train)

print(f"Best params: {clf_cv.best_params_}")
print(f"Best CV AUC: {clf_cv.best_score_:.3f}")
best_model = clf_cv.best_estimator_
print(best_model)

#####################################################################

# Calculate metrics
train_acc = accuracy_score(y_train, y_train_pred)
train_auc = roc_auc_score(y_train, y_train_prob)

print("ðŸ“Š TRAINING SET PERFORMANCE")
print("=" * 40)
print(f"Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)")
print(f"AUC: {train_auc:.4f}")
print("\nClassification Report:")
print(classification_report(y_train, y_train_pred, target_names=['Healthy', 'Cancer']))

cm = confusion_matrix(y_test, y_test_pred)

plt.figure(figsize=(6, 5))
ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                 xticklabels=['Healthy', 'Cancer'],
                 yticklabels=['Healthy', 'Cancer'])

plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix - Test Set')

fig = ax.get_figure()
fig.savefig("confusion_matrix_xgb.png", dpi=300, bbox_inches='tight')

plt.show()


# Predict probabilities for ROC
y_train_proba = clf_cv.predict_proba(X_train)[:, 1]
y_test_proba  = clf_cv.predict_proba(X_test)[:, 1]

# Compute ROC curve + AUC
fpr_train, tpr_train, _ = roc_curve(y_train, y_train_proba)
fpr_test, tpr_test, _   = roc_curve(y_test, y_test_proba)

train_auc = auc(fpr_train, tpr_train)
test_auc  = auc(fpr_test, tpr_test)

# Plot ROC curves
plt.figure(figsize=(7, 6))
plt.plot(fpr_train, tpr_train, label=f"Train ROC (AUC = {train_auc:.3f})")
plt.plot(fpr_test,  tpr_test,  label=f"Test ROC  (AUC = {test_auc:.3f})")

# Random classifier line
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")

plt.xlabel("False Positive Rate", fontsize = 13)
plt.ylabel("True Positive Rate", fontsize = 13)
plt.title("ROC Curve - XGBoost")
plt.legend()
plt.grid(alpha=0.3)

plt.savefig("roc_curve_xgb.png", dpi=600, bbox_inches='tight')
plt.show()


