import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
#import shap

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score,
    roc_auc_score,
    roc_curve,
    confusion_matrix,
    classification_report
)

# Set random seed for reproducibility
RANDOM_STATE = 13
np.random.seed(RANDOM_STATE)

#################################################################
X_boot, X_val, y_boot, y_val = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=RANDOM_STATE
)

def stratified_bootstrap(X, y, random_state=None):
    """
    Return (X_resampled, y_resampled) with correct stratified sampling.
    Works for pandas DataFrame/Series.
    """
    rng = np.random.RandomState(random_state)
    classes = np.unique(y)

    sampled_indices = []

    for c in classes:
        idx_c = np.where(y == c)[0]        # row positions
        sampled_c = rng.choice(idx_c, size=len(idx_c), replace=True)
        sampled_indices.append(sampled_c)

    sampled_indices = np.concatenate(sampled_indices)
    rng.shuffle(sampled_indices)

    return X.iloc[sampled_indices], y.iloc[sampled_indices]


############################################

n_bootstrap = 1000
bootstrap_results = {
    "C parameters": [],
    "PCA components": [],
    "train AUC": [],
    "test AUC": [],
    "train accuracy": [],
    "test accuracy": [],
    "train probs": [],     # <--- Added
    "test probs": [],      # <--- Added
    "test true": []        # <--- Added
}

for i in range(n_bootstrap):
    # 1) Stratified bootstrap 
    X_resampled, y_resampled = stratified_bootstrap(X_boot, y_boot, random_state=i)

    # 2) Train/test split
    X_resampled_train, X_resampled_test, y_resampled_train, y_resampled_test = train_test_split(
        X_resampled,
        y_resampled,
        test_size=0.2,
        random_state=42,
        stratify=y_resampled
    )

    # 3) Pipeline
    pipe = Pipeline([
        ("scaling", StandardScaler()),
        ("pca", PCA(random_state=RANDOM_STATE)),
        ("classifier", LogisticRegression(
            class_weight='balanced',
            max_iter=500,
            random_state=RANDOM_STATE,
            solver='saga',
            penalty="l2"
        ))
    ])

    # 4) Grid search
    param_grid = {
        'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],
        'pca__n_components': [10, 20, 30, 50, 75, 100]
    }

    clf_cv = GridSearchCV(
        pipe,
        param_grid=param_grid,
        cv=10,
        scoring='roc_auc',
        n_jobs=-1,
        verbose=1,
        refit=True
    )

    clf_cv.fit(X_resampled_train, y_resampled_train)

    best_c = clf_cv.best_params_["classifier__C"]
    best_n_components = clf_cv.best_params_["pca__n_components"]
    best_model = clf_cv.best_estimator_

    # --- Probabilities and metrics ---
    y_train_prob = best_model.predict_proba(X_resampled_train)[:, 1]
    y_train_pred = (y_train_prob > 0.5).astype(int)
    train_acc = accuracy_score(y_resampled_train, y_train_pred)
    train_auc = roc_auc_score(y_resampled_train, y_train_prob)

    y_test_prob = best_model.predict_proba(X_resampled_test)[:, 1]
    y_test_pred = (y_test_prob > 0.5).astype(int)
    test_acc = accuracy_score(y_resampled_test, y_test_pred)
    test_auc = roc_auc_score(y_resampled_test, y_test_prob)

    # Store everything
    bootstrap_results["C parameters"].append(best_c)
    bootstrap_results["PCA components"].append(best_n_components)
    bootstrap_results["train AUC"].append(train_auc)
    bootstrap_results["test AUC"].append(test_auc)
    bootstrap_results["train accuracy"].append(train_acc)
    bootstrap_results["test accuracy"].append(test_acc)

    bootstrap_results["train probs"].append(y_train_prob)
    bootstrap_results["test probs"].append(y_test_prob)
    bootstrap_results["test true"].append(y_resampled_test.values)

#################################################################
fprs = []
tprs = []

for y_true, y_prob in zip(bootstrap_results["test true"], bootstrap_results["test probs"]):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    fprs.append(fpr)
    tprs.append(tpr)

import numpy as np
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

# Collect FPR/TPR values across all bootstraps
mean_fpr = np.linspace(0, 1, 200)  # fixed grid for interpolation
tprs = []
aucs = []

for y_true, y_prob in zip(bootstrap_results["test true"], bootstrap_results["test probs"]):
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    
    # Interpolate TPR at common FPR points
    tpr_interp = np.interp(mean_fpr, fpr, tpr)
    tpr_interp[0] = 0.0
    tprs.append(tpr_interp)

# Convert to numpy
tprs = np.array(tprs)

# Compute mean ROC and 95% CI
mean_tpr = tprs.mean(axis=0)
std_tpr = tprs.std(axis=0)

# 95% confidence interval
tpr_upper = np.minimum(mean_tpr + 1.96 * std_tpr, 1)
tpr_lower = np.maximum(mean_tpr - 1.96 * std_tpr, 0)

# Final mean AUC
from sklearn.metrics import roc_auc_score
mean_auc = np.mean(bootstrap_results["test AUC"])
std_auc = np.std(bootstrap_results["test AUC"])

# --- Plot ---
plt.figure(figsize=(8, 6))

# CI band
plt.fill_between(
    mean_fpr,
    tpr_lower,
    tpr_upper,
    alpha=0.25,
    label='95% Confidence Interval'
)

# Mean ROC curve
plt.plot(
    mean_fpr,
    mean_tpr,
    lw=2,
    label=f"Mean ROC (AUC = {mean_auc:.3f} Â± {std_auc:.3f})"
)

# Diagonal line
plt.plot([0, 1], [0, 1], linestyle='--', color='grey')

plt.xlabel("False Positive Rate", fontsize = 13)
plt.ylabel("True Positive Rate", fontsize = 13)
plt.title("ROC Curve with 95% Confidence Interval (Bootstrap) - Logisitic Regression")
plt.legend(loc="lower right")
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig("ROC_plot_logisitc.png")
plt.show()

#################################################################

#################################################################
